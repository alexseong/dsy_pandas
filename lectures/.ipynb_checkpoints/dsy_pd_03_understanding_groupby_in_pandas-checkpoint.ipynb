{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSTANDING GROUPBY IN PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv file\n",
    "data = pd.DataFrame.from_csv('../data/phone_data.csv')\n",
    "# Convert date from string to date times\n",
    "data['date'] = data['date'].apply(dateutil.parser.parse, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows the dataset\n",
    "data['item'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the longest phone call / data entry?\n",
    "data['duration'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many seconds of phone calls are recorded in total?\n",
    "data['duration'][data['item'] == 'call'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many entries are there for each month?\n",
    "data['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of non-null unique network entries\n",
    "data['network'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The need for custom functions is minimal unless you have very specific requirements. The full range of basic statistics that are quickly calculable and built into the base Pandas package are:\n",
    "\n",
    "- count: Number of non-null observations\n",
    "- sum: Sum of values\n",
    "- mean: Mean of values\n",
    "- mad: Mean absolute deviation\n",
    "- median: Arithmetic median of values\n",
    "- min: Minimum\n",
    "- max: Maximum\n",
    "- mode: Mode\n",
    "- abs: Absolute Value\n",
    "- prod: Product of values\n",
    "- std: Unbiased standard deviation\n",
    "- var: Unbiased variance\n",
    "- sem: Unbiased standard error of the mean\n",
    "- skew: Unbiased skewness (3rd moment)\n",
    "- kurt: Unbiased kurtosis (4th moment)\n",
    "- quantile: Sample quantile (value at %)\n",
    "- cumsum: Cumulative sum\n",
    "- cumprod: Cumulative product\n",
    "- cummax: Cumulative maximum\n",
    "- cummin: Cumulative minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: SUMMARIZING GROUPS IN THE DATAFRAME\n",
    "\n",
    "There’s further power put into your hands by mastering the Pandas “groupby()” functionality. Groupby essentially splits the data into different groups depending on a variable of your choice. For example, the expression  data.groupby('month') will split our current DataFrame by month.\n",
    "\n",
    "The groupby() function returns a GroupBy object, but essentially describes how the rows of the original data set has been split. the GroupBy object .groups variable is a dictionary whose keys are the computed unique groups and corresponding values being the axis labels belonging to each group. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['month']).groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.groupby(['month']).groups['2014-11'])\n",
    "data.groupby(['month']).groups['2014-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first entry for each month\n",
    "data.groupby('month').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sum of the durations per month\n",
    "data.groupby('month')['duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of dates / entries in each month\n",
    "data.groupby('month')['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the sum of durations, for calls only, to each network\n",
    "data[data['item'] == 'call'].groupby('network')['duration'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also group by more than one variable, allowing more complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many calls, sms, and data entries are in each month?\n",
    "data.groupby(['month', 'item'])['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many calls, texts, and data are sent per month, split by network_type?\n",
    "data.groupby(['month', 'network_type'])['date'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: GROUPBY OUTPUT FORMAT - SERIES OR DATAFRAME?\n",
    "\n",
    "The output from a groupby and aggregation operation varies between Pandas Series and Pandas Dataframes, which can be confusing for new users. As a rule of thumb, if you calculate more than one column of results, your result will be a Dataframe. For a single column of results, the agg function, by default, will produce a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('month')['duration'].sum() # produces Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('month')[['duration']].sum() # Produces Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The groupby output will have an index or multi-index on rows corresponding to your chosen grouping variables. To avoid setting this index, pass “as_index=False” to the groupby operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('month', as_index=False).agg({\"duration\": \"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the as_index parameter while Grouping data in pandas prevents setting a row index on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: MULTIPLE STATISTICS PER GROUP\n",
    "\n",
    "The final piece of syntax that we’ll examine is the “agg()” function for Pandas. The aggregation functionality provided by the agg() function allows multiple statistics to be calculated per group in one calculation. The syntax is simple, and is similar to that of MongoDB’s [aggregation framework](http://docs.mongodb.org/manual/applications/aggregation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/pandas_aggregation-1024x409.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation of variables in a Pandas Dataframe using the agg() function. Note that in Pandas versions 0.20.1 onwards, the renaming of results needs to be done separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4: APPLYING A SINGLE FUNCTION TO COLUMNS IN GROUPS\n",
    "\n",
    "Instructions for aggregation are provided in the form of a python dictionary or list. The dictionary keys are used to specify the columns upon which you’d like to perform operations, and the dictionary values to specify the function to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by month and item and extract a number of stats from each group\n",
    "data.groupby(['month', 'item']).agg({'duration':sum,      # find the sum of the durations for each group\n",
    "                                     'network_type': \"count\", # find the number of network type entries\n",
    "                                     'date': 'first'})    # get the first date per group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregation dictionary syntax is flexible and can be defined before the operation. You can also define functions inline using “lambda” functions to extract statistics that are not provided by the built-in options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregation procedure outside of the groupby operation\n",
    "aggregations = {\n",
    "    'duration':'sum',\n",
    "    'date': lambda x: max(x) - pd.Timedelta(seconds=60)\n",
    "}\n",
    "data.groupby('month').agg(aggregations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 5: APPLYING MULTIPLE FUNCTIONS TO COLUMNS IN GROUPS\n",
    "\n",
    "To apply multiple functions to a single column in your grouped data, expand the syntax above to pass in a list of functions as the value in your aggregation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data frame by month and item and extract a number of stats from each group\n",
    "data.groupby(['month', 'item']).agg({'duration': [min, max, sum],      # find the min, max, and sum of the duration column\n",
    "                                     'network_type': \"count\", # find the number of network type entries\n",
    "                                     'date': [min, 'first', 'nunique']})    # get the min, first, and number of unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 6: RENAMING GROUPED STATISTICS FROM GROUPBY OPERATIONS\n",
    "\n",
    "When multiple statistics are calculated on columns, the resulting dataframe will have a multi-index set on the column axis. This can be difficult to work with, and I typically have to rename columns after a groupby operation.\n",
    "\n",
    "One option is to drop the top level (using .droplevel) of the newly created multi-index on columns using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "grouped = data.groupby('month').agg({\"duration\":[min, max, np.mean]})\n",
    "grouped.columns = grouped.columns.droplevel(level=0)\n",
    "grouped.rename(columns={\"min\": \"min_duration\", \"max\": \"max_duration\", \"mean\": \"mean_duration\"})\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this approach loses the original column names, leaving only the function names as column headers. A neater approach is using the ravel() method on the grouped columns. Ravel() turns a Pandas multi-index into a simpler array, which we can combine into sensible column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby('month').agg({\"duration\":[min, max, np.mean]})\n",
    "# Using ravel, and a string join, we can create better names for the columns:\n",
    "grouped.columns = [\"_\".join(x) for x in grouped.columns.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick renaming of grouped columns from the groupby() multi-index can be achieved using the ravel() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 7: MAP, REDUCE, AND FILTER IN AGGREGATE METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_list = [['Item A', 59],\n",
    "          ['Item B', 95],\n",
    "          ['Item B', 82],\n",
    "          ['Item C', 40],\n",
    "          ['Item A', 11]]\n",
    "\n",
    "medium = pd.DataFrame(medium_list)\n",
    "medium.columns = ['item', 'value']\n",
    "medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the above DataFrame each row is an item of type A, B or C and its value. A common task would be to know how much value you’ve got for each type of item. In order to do this, you just group by item and sum the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium.groupby('item').value.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case it’s pretty straight forward. We’ve got a sum function from Pandas that does the work for us. If there wasn’t such a function we could make a custom sum function and use it with the aggregate function in order to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce \n",
    "\n",
    "def test_sum(series):\n",
    "    return reduce(lambda x, y: x + y, series.tolist())\n",
    "\n",
    "medium.groupby('item').agg({'value': ['sum', test_sum]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregation function we created receives the value Series from the DataFrame and them sums all the items from the series to get the same result as the sum function from Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this is a dull example, as it’s not useful at all given the existence of the sum function. In a real world use case, when we want to verify if every sales analyst is tied to a manager, we can create the following aggregation function in order to return the set of every analyst for a given manager.\n",
    "\n",
    "~~~\n",
    "def agg_analyst_per_manager(series):\n",
    "  analyst_list = series.astype(unicode).tolist()\n",
    "  analyst_list = filter(lambda analyst: analyst != '', analyst_list)\n",
    "  return set(analyst_list)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "\n",
    "The groupby functionality in Pandas is well documented in the [official docs](http://pandas.pydata.org/pandas-docs/stable/groupby.html) and performs at speeds on a par (unless you have massive data and are picky with your milliseconds) with R’s data.table and dplyr libraries.\n",
    "\n",
    "There are plenty of resources online on this functionality, and we’d recommomend really conquering this syntax if you’re using Pandas in earnest at any point.\n",
    "\n",
    "1. [DataQuest Tutorial on Data Analysis]( https://www.dataquest.io/blog/pandas-tutorial-python-2/)\n",
    "2. [Chris Albon notes on Groups]( https://chrisalbon.com/python/pandas_apply_operations_to_groups.html)\n",
    "3. [Greg Reda Pandas Tutorial]( http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
